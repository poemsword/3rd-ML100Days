{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"Day_040_HW.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"J1QBgxfCaMr_","colab_type":"text"},"source":["## [作業重點]\n","使用 Sklearn 中的 Lasso, Ridge 模型，來訓練各種資料集，務必了解送進去模型訓練的**資料型態**為何，也請了解模型中各項參數的意義。\n","\n","機器學習的模型非常多種，但要訓練的資料多半有固定的格式，確保你了解訓練資料的格式為何，這樣在應用新模型時，就能夠最快的上手開始訓練！"]},{"cell_type":"markdown","metadata":{"id":"h9Wh3eBdaMsA","colab_type":"text"},"source":["## 練習時間\n","試著使用 sklearn datasets 的其他資料集 (boston, ...)，來訓練自己的線性迴歸模型，並加上適當的正則化來觀察訓練情形。"]},{"cell_type":"code","metadata":{"id":"tKVuJaHwaXds","colab_type":"code","colab":{}},"source":["####  載入套件\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import datasets, linear_model\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8oKgI9fVaR-e","colab_type":"text"},"source":["**wine 資料集**"]},{"cell_type":"code","metadata":{"id":"EGfRKFiTaMsA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600163438551,"user_tz":-480,"elapsed":1257,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHJjxHE8c1eY_tctZujH1y425CWl0lLqez0rmj=s64","userId":"12918198997909807777"}},"outputId":"832f7b50-1499-41d6-8a87-4ef0b6c917bc"},"source":["data_wine = datasets.load_wine()\n","\n","##  x\n","x = pd.DataFrame(data_wine.data)\n","x.columns = data_wine.feature_names\n","x.head()\n","\n","##  y\n","y = pd.Series(data_wine.target)\n","y.columns = data_wine.target_names\n","y.unique()\n","\n","##  切割資料集\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=4)\n","\n","print(\"shape of x_train is\", x_train.shape)\n","print(\"shape of x_test is\", x_test.shape)\n","print(\"shape of y_train is\", y_train.shape)\n","print(\"shape of y_test is\", y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["shape of x_train is (160, 13)\n","shape of x_test is (18, 13)\n","shape of y_train is (160,)\n","shape of y_test is (18,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yEFY4o0wenD0","colab_type":"text"},"source":["**wine + 一般羅吉斯**"]},{"cell_type":"code","metadata":{"id":"RWuE0J4FeZzP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1600163445008,"user_tz":-480,"elapsed":722,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHJjxHE8c1eY_tctZujH1y425CWl0lLqez0rmj=s64","userId":"12918198997909807777"}},"outputId":"3faee0b7-a638-457e-d1e9-79c082f25294"},"source":["# 建立一個羅吉斯模型\n","logreg = linear_model.LogisticRegression(multi_class='multinomial')\n","\n","# 將訓練資料丟進去模型訓練\n","logreg.fit(x_train, y_train)\n","\n","# 將測試資料丟進模型得到預測結果\n","y_pred = logreg.predict(x_test)\n","\n","# 看預測結果\n","acc = accuracy_score(y_test, y_pred)\n","print(\"Accuracy: \", acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy:  0.8888888888888888\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"R50To3X906Qs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1600163447998,"user_tz":-480,"elapsed":1582,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHJjxHE8c1eY_tctZujH1y425CWl0lLqez0rmj=s64","userId":"12918198997909807777"}},"outputId":"ea6f5770-1f08-4143-c30f-4efbcae82ee6"},"source":["# 印出各特徵對應的係數\n","logreg.coef_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-1.03404985e-01,  2.10423498e-01,  1.49013598e-01,\n","        -1.82029990e-01, -4.72691600e-02,  2.63392042e-01,\n","         5.11596987e-01, -3.69936801e-02,  1.04959966e-01,\n","        -1.89285133e-02, -7.17517988e-03,  3.80730644e-01,\n","         9.25556067e-03],\n","       [ 4.90134737e-01, -7.05991076e-01, -1.39712832e-01,\n","         1.61086307e-01,  1.91674591e-02,  1.98993175e-01,\n","         3.81316615e-01,  4.64161063e-02,  2.61452108e-01,\n","        -1.18521990e+00,  2.48688029e-01,  3.76344339e-01,\n","        -8.98984422e-03],\n","       [-3.86729752e-01,  4.95567578e-01, -9.30076660e-03,\n","         2.09436831e-02,  2.81017008e-02, -4.62385217e-01,\n","        -8.92913602e-01, -9.42242614e-03, -3.66412075e-01,\n","         1.20414842e+00, -2.41512850e-01, -7.57074983e-01,\n","        -2.65716453e-04]])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"CQmm_UEr1Yr3","colab_type":"text"},"source":["**wine + L2 羅吉斯 (L1必須搭配solver=liblinear 但 multi_class=multinomial 又不能使用 solver=liblinear)**\n","\n","結果相同，原本預設就是用 L2"]},{"cell_type":"code","metadata":{"id":"XD9N8kM81fdU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1600163453639,"user_tz":-480,"elapsed":2096,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHJjxHE8c1eY_tctZujH1y425CWl0lLqez0rmj=s64","userId":"12918198997909807777"}},"outputId":"a0f969cb-c457-4da9-ce37-f92f4a1c5d7f"},"source":["# 建立一個羅吉斯模型\n","logreg = linear_model.LogisticRegression(multi_class='multinomial', penalty='l2')\n","\n","# 將訓練資料丟進去模型訓練\n","logreg.fit(x_train, y_train)\n","\n","# 將測試資料丟進模型得到預測結果\n","y_pred = logreg.predict(x_test)\n","\n","# 看預測結果\n","acc = accuracy_score(y_test, y_pred)\n","print(\"Accuracy: \", acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy:  0.8888888888888888\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2aTMCtaG6nIP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1600163455679,"user_tz":-480,"elapsed":832,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHJjxHE8c1eY_tctZujH1y425CWl0lLqez0rmj=s64","userId":"12918198997909807777"}},"outputId":"cdf2f538-a46b-4578-93e2-9344eb949b21"},"source":["# 印出各特徵對應的係數\n","logreg.coef_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-1.03404985e-01,  2.10423498e-01,  1.49013598e-01,\n","        -1.82029990e-01, -4.72691600e-02,  2.63392042e-01,\n","         5.11596987e-01, -3.69936801e-02,  1.04959966e-01,\n","        -1.89285133e-02, -7.17517988e-03,  3.80730644e-01,\n","         9.25556067e-03],\n","       [ 4.90134737e-01, -7.05991076e-01, -1.39712832e-01,\n","         1.61086307e-01,  1.91674591e-02,  1.98993175e-01,\n","         3.81316615e-01,  4.64161063e-02,  2.61452108e-01,\n","        -1.18521990e+00,  2.48688029e-01,  3.76344339e-01,\n","        -8.98984422e-03],\n","       [-3.86729752e-01,  4.95567578e-01, -9.30076660e-03,\n","         2.09436831e-02,  2.81017008e-02, -4.62385217e-01,\n","        -8.92913602e-01, -9.42242614e-03, -3.66412075e-01,\n","         1.20414842e+00, -2.41512850e-01, -7.57074983e-01,\n","        -2.65716453e-04]])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"bBXzTnGd67Mv","colab_type":"text"},"source":["**boston 資料集**"]},{"cell_type":"code","metadata":{"id":"wlh8c-Ph6-q3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600163526369,"user_tz":-480,"elapsed":875,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHJjxHE8c1eY_tctZujH1y425CWl0lLqez0rmj=s64","userId":"12918198997909807777"}},"outputId":"bd01daa7-bcd8-48f8-af6c-df29802217cb"},"source":["data_boston = datasets.load_boston()\n","\n","##  x\n","x = pd.DataFrame(data_boston.data)\n","x.columns = data_boston.feature_names\n","x.head()\n","\n","##  y\n","y = pd.Series(data_boston.target)\n","y.unique()\n","\n","##  切割資料集\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=4)\n","\n","print(\"shape of x_train is\", x_train.shape)\n","print(\"shape of x_test is\", x_test.shape)\n","print(\"shape of y_train is\", y_train.shape)\n","print(\"shape of y_test is\", y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["shape of x_train is (455, 13)\n","shape of x_test is (51, 13)\n","shape of y_train is (455,)\n","shape of y_test is (51,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hEp0xjS18QJ7","colab_type":"text"},"source":["boston + 一般迴歸"]},{"cell_type":"code","metadata":{"id":"QRleVtps7DnF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1600163529280,"user_tz":-480,"elapsed":921,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHJjxHE8c1eY_tctZujH1y425CWl0lLqez0rmj=s64","userId":"12918198997909807777"}},"outputId":"bdf34842-80d6-4161-9a7c-3657bd4acb00"},"source":["# 建立一個線性回歸模型\n","regr = linear_model.LinearRegression()\n","\n","# 將訓練資料丟進去模型訓練\n","regr.fit(x_train, y_train)\n","\n","# 將測試資料丟進模型得到預測結果\n","y_pred = regr.predict(x_test)\n","\n","# 印出係數\n","print(regr.coef_, \"\\n\")\n","\n","# 預測值與實際值的差距，使用 MSE\n","print(\"Mean squared error: %.2f\"\n","      % mean_squared_error(y_test, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[-1.25856659e-01  4.84257396e-02  1.84085281e-02  3.08509569e+00\n"," -1.73277018e+01  3.61674713e+00  2.19181853e-03 -1.49361132e+00\n","  3.19979200e-01 -1.27294649e-02 -9.27469086e-01  9.50912468e-03\n"," -5.33592471e-01] \n","\n","Mean squared error: 17.04\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CMbnuGhM8T_S","colab_type":"text"},"source":["boston + Lasso 迴歸 (L1)：\n","係數變少且 MSE 上升"]},{"cell_type":"code","metadata":{"id":"HB1JjXw48oTk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1600163541813,"user_tz":-480,"elapsed":1429,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHJjxHE8c1eY_tctZujH1y425CWl0lLqez0rmj=s64","userId":"12918198997909807777"}},"outputId":"a7736a19-f5a3-4358-a39c-91e041fca386"},"source":["# 建立一個線性回歸模型\n","lasso = linear_model.Lasso(alpha=1.0)\n","\n","# 將訓練資料丟進去模型訓練\n","lasso.fit(x_train, y_train)\n","\n","# 將測試資料丟進模型得到預測結果\n","y_pred = lasso.predict(x_test)\n","\n","# 印出係數\n","print(lasso.coef_, \"\\n\")\n","\n","# 預測值與實際值的差距，使用 MSE\n","print(\"Mean squared error: %.2f\"\n","      % mean_squared_error(y_test, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[-0.07256057  0.04967103 -0.          0.         -0.          0.80886056\n","  0.02328171 -0.68444051  0.26862528 -0.01526566 -0.71692899  0.00828412\n"," -0.77123108] \n","\n","Mean squared error: 23.24\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D6U8LqU69DKe","colab_type":"text"},"source":["boston + Ridge Regression (L2)：\n","係數沒有像 L1 一樣變少，只有係數變小，且 MSE 上升"]},{"cell_type":"code","metadata":{"id":"d6GAW0nd9K8-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1600163557533,"user_tz":-480,"elapsed":833,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHJjxHE8c1eY_tctZujH1y425CWl0lLqez0rmj=s64","userId":"12918198997909807777"}},"outputId":"3aea075c-6917-4198-bf52-457384c9e351"},"source":["# 建立一個線性回歸模型\n","ridge = linear_model.Ridge(alpha=1.0)\n","\n","# 將訓練資料丟進去模型訓練\n","ridge.fit(x_train, y_train)\n","\n","# 將測試資料丟進模型得到預測結果\n","y_pred = ridge.predict(x_test)\n","\n","# 印出係數\n","print(ridge.coef_, \"\\n\")\n","\n","# 預測值與實際值的差距，使用 MSE\n","print(\"Mean squared error: %.2f\"\n","      % mean_squared_error(y_test, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[-1.22488037e-01  4.95483049e-02 -1.15839833e-02  2.89071820e+00\n"," -1.00402895e+01  3.66674306e+00 -4.43653915e-03 -1.38990862e+00\n","  3.02286292e-01 -1.32259798e-02 -8.52141794e-01  9.86708353e-03\n"," -5.43681130e-01] \n","\n","Mean squared error: 17.35\n"],"name":"stdout"}]}]}