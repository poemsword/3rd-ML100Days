{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"Day_039_HW.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"k7q3jY_iTotJ","colab_type":"text"},"source":["## [作業重點]\n","清楚了解 L1, L2 的意義與差異為何，並了解 LASSO 與 Ridge 之間的差異與使用情境"]},{"cell_type":"markdown","metadata":{"id":"9iHPK-RATotL","colab_type":"text"},"source":["## 作業"]},{"cell_type":"markdown","metadata":{"id":"ziUuVXekTotL","colab_type":"text"},"source":["請閱讀相關文獻，並回答下列問題\n","\n","[脊回歸 (Ridge Regression)](https://blog.csdn.net/daunxx/article/details/51578787)\n","[Linear, Ridge, Lasso Regression 本質區別](https://www.zhihu.com/question/38121173)\n","\n","1. LASSO 回歸可以被用來作為 Feature selection 的工具，請了解 LASSO 模型為什麼可用來作 Feature selection\n","2. 當自變數 (X) 存在高度共線性時，Ridge Regression 可以處理這樣的問題嗎?\n"]},{"cell_type":"markdown","metadata":{"id":"TU3cAHiTXb1M","colab_type":"text"},"source":["**A1：在建模的時候當加入因子不斷增加時，雖然擬合程度隨著模型複雜程度不斷上升而一同上升，但同時也不知不覺將誤差(噪音)一起擬合了。LASSO迴歸的目標函數多加了一個 L1 懲罰項，當變數不斷增加時除了重視模型的擬合能力，同時也考慮了泛化能力，故使用LASSO迴歸建模可挑選出相對能捕捉 Y signal 而非 noise 的因子**"]},{"cell_type":"markdown","metadata":{"id":"PHZrxKzIYbj_","colab_type":"text"},"source":["**A2：可以，如果自變數間存在高度共線性，那表示其實有些變數是多餘放入的，事實上不須放這麼多變數同樣能捕捉到一樣的資訊。在懲罰項的作用下可以有效地減少多餘的因子，減少模型過度擬合噪音的情形，增加模型的泛化能力**"]}]}